# Link to website
https://cse134b-99bb5.firebaseapp.com/
# Question 1. Introduction to Web Technologies (3 points)
6. 
![homepage](/pictures/homepage.png)
7. Linked above



# Question 2. Chrome DevTools - Network (4 points)
1. \# of Requests by Content Type: 
    1. JS: 1
    2. CSS: 1ÃŸ
    3. Img: 4
    4. Media: 1
    5. Font: 1
    6. Doc: 1
    7. Other: 1
2. Total # of Requests: 10
3. Total Bytes Sent: 66
4. 
![waterfall](/pictures/waterfall.png)

# Question 3. Client-Side Inherently Insecure Demo (1 point)
1. 
![6](/pictures/6.png)


# Part 2
1. HTTP Response Headers 
UCI's responce HTTP's headers are concerning because the 
Strict-Transport-Security is set to "max-age=31536000; includeSubDomains". 
This means that the broswer waits the set about of time before remembering
that a site should only be accessed using HTTPS. This is important because
HTTPS add encryption on top of HTTP.

2. JavaScript Off
    1. With Javscript
    ![UCSDJS](/pictures/UCSDJS.png)
    Without Javascript
    ![UCSDNOJS](/pictures/UCSDNOJS.png)
    2. By disabling javaScript, the navigation bar does not function with a drop down menu on UCSD's site.
    3. With Javascript
    ![UCLAJS](/pictures/UCLAJS.png)
    Without Javascript
    ![UCLANOJS](/pictures/UCLANOJS.png)
    4. By disabling javaScript, you cannot view or click any links under the events section on UCLA's site

3. Custom vs. Default 404 Pages
    1. Yes
    2. https://www.csuci.edu/asdf
    3. No
    4. https://jpcatholic.edu/asdf
    5. Custom 404 pages are important because it gives the users a better experience.
    If the page defaults to a regular 404 page, then the user will not be able to
    navigate to the home page. Additionally, users will get turned off by the error,
    and leave the site. Custom 404 errors can also hide away server details that
    hackers can use to exploit servers.

4. Search Engines - robots.txt
    1. yes, ![UCSDrob](/pictures/UCSDrob.png)
    2. no, ![cathrob](/pictures/cathrob.png)
    3. If hackers have access to robots.txt file, then they could figure out which URLs have sensitive data.

5. Search Engines - Google Hacking
    1. Google hacking involves using certain queries on google search to find sensitive information about sites. This can be used to find logs that contain passwords on websites, which can be used for hacking.
    2. It is troubling because the google bot crawls websites, which may not be secure, and index pages that contain sensitive information. This means that these pages are accessible using certain query operations.
    3. As web developers, we need to ensure that pages that contain private information should not be indexed by google.
    4. This question is related to question 4 because the robots.txt file can help us ensure that private pages will not crawled by google bot. 

6. Search Engines - Google Results Reality Check 
    1. About 1,470,000 results (0.57 seconds) 
    2. No
    3. The purpose of this question was to highlight how the relevance of a google search degrades by ranking. For instance, URLs that appear on the first page are more relevant than pages on the 10th page.

7. Chrome DevTools - JavaScript Console and Local Storage
    1. ![medium](/pictures/medium.png)
    2. They put their hiring link because it could be used to find developers that are somewhat competent (Hiring link still shows up on google tho).
    ![localhost](/pictures/localhost.png)
    3. These values are set and used by the broswer so that it can remembered even after the broswer is closed. For instance, login information can be stored in local host, so that the user doesn't have to login in again after closing the site. 

8. Chrome DevTools - Console and Source
    1. datasetCount
    2. It could be included for debugging purposes, so that its easier to keep track of this value. However, it may be more
    appropriate to comment and umcomment this line.
    3. It might cause errors or function differently on different browsers.

9. Chrome DevTools - User Agent Header
    1. Yes, it looks different. 
    2. Desktop version
    ![desktop](/pictures/desktop.png)
    Iphone
    ![iphone](/pictures/iphone.png)
    The major differences is that the desktop version includes frequently visisted sites. While the iphone version includes trending searches.

10. 
11. Chrome DevTools - Performance Test
    1. ![UCSDper](/pictures/UCSDper.png)
    2. Eliminate render-blocking resources: 
    3. 
    4. SDSU
12.
13.
14.
15.

